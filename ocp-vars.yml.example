---
##############################################################################
# Red Hat Virtualization Engine Connection
##############################################################################
#engine_url: https://engine.example.com/ovirt-engine/api
engine_hostname: rhvm.foo.bar
engine_url: "https://{{ engine_hostname }}/ovirt-engine/api"
engine_user: admin@internal
engine_password: ''
# CA file copied from engine:/etc/pki/ovirt-engine/ca.pem; path is relative to playbook directory
#curl -k 'https://engine.example.com/ovirt-engine/services/pki-resource?resource=ca-certificate&format=X509-PEM-CA' > ca.pem
engine_cafile: files/ca.pem

##############################################################################
# Red Hat Virtualization VM Image
# For CentOS 7:
##############################################################################
#qcow_url: https://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
## For RHEL: Find KVM Guest Image in Downloads -> RHEL on https://access.redhat.com/ and use before the link expires:
#qcow_url:https://access.cdn.redhat.com//content/origin/files/<omitted>/rhel-server-7.4-x86_64-kvm.qcow2?_auth_=<omitted>
## Alternatively, download the above KVM image, and re-host it on a local satellite:
#qcow_url: https://satellite.example.com/pub/rhel-server-7.4-x86_64-kvm.qcow2
# or download and host locally on webserver accessible
qcow_url: file:///vagrant/iso/rhel-server-7.5-x86_64-kvm.qcow2

# Name of cluster to install on
rhv_cluster: Default
# Name of Datacenter to install on
rhv_data_center: Default

# VM Network to attach to if undefined defaults to ovirtmgmt
rhv_vm_network: "ovirtmgmt"

## Name of RHV storage domain to create disks
rhv_data_storage: vmdata
##############################################################################
# OverRides
#vm_infra_wait_for_ip_delay: 180
#vm_infra_wait_for_ip_retries: 10
#
###############################################################################
## VM configurations
###############################################################################
###############################################################################
## TEMPLATE CONFIG
## rhel qcow template
template_cluster: "{{ rhv_cluster }}"
template_name: rhel7_5
template_memory: 4GiB
template_cpu: 1
template_disk_storage: "{{ rhv_data_storage }}"
template_disk_size: 30GiB
template_nics:
    - name: nic1
      profile_name: "{{ rhv_vm_network | default('ovirtmgmt') }}"
      interface: virtio

##############################################################################
# VM Node Sizing
##############################################################################
vm_state: running
master_vm_mem: 8
master_vm_vcpu: 2
master_docker_volume_size: '10'
master_local_volume_size: '10'
master_etcd_volume_size: '10'

infra_vm_mem:  "{{ master_vm_mem }}"
infra_vm_vcpu: "{{ master_vm_vcpu }}"
infra_docker_volume_size: "{{ master_docker_volume_size }}"
infra_local_volume_size: "{{ master_local_volume_size }}"

node_vm_mem:  "{{ master_vm_mem }}"
node_vm_vcpu: "{{ master_vm_vcpu }}"
node_docker_volume_size: "{{ master_docker_volume_size }}"
node_local_volume_size: "{{ master_local_volume_size }}"

##############################################################################
# Red Hat Content Subscriptions
##############################################################################
## For subscriptions to Red Hat's CDN
## Userid/Password could be moved to a vault file and encrypted for safety, see the following link for details:
## http://docs.ansible.com/ansible/playbooks_vault.html
#rhsm_user: ""
#rhsm_pass: ""
rhsm_key: ""
rhsm_org: ""

## Can specify separate pools so only Application nodes use paid subs
## or keep the same if only using one pool
rhsm_broker_pool: ""
rhsm_node_pool: ""
## For Openshift Container Storage
rhsm_ocs_pool: ""

# satellite server
#rhsm_satellite: ''
#rhsm_katello_url: 'url for to download katello from local satellite'

## registry authentication when using registry.redhat.io
oreg_auth_user: ''
oreg_auth_password: ''
rhsm_repos:
  - rhel-7-server-rpms
  - rhel-7-server-extras-rpms
  - rhel-7-server-ose-3.11-rpms
  - rhel-7-server-ansible-2.6-rpms
bastion_pkgs:
  - ansible
  - atomic-openshift-clients
  - git
  - tmux
  - screen
##############################################################################
# PUBLIC SSH key for access to all nodes.
# Use ssh-agent or a passwordless key in ~/.ssh/id_rsa for the PRIVATE key.
# paste the pub key you want to inject in all nodes so you can ssh
##############################################################################
root_ssh_key: ""

##############################################################################
##############################################################################
#    Openshift VARIABLES
##############################################################################
# Most defaults are sane and will result in OCP3.9 Deployed with CNS
##############################################################################

# Choices of deployment type: openshift-enterprise, origin
containerized: false
console_port: 443
debug_level: 2

admin_user: root

# Number of App nodes
master_nodes: 3
infra_nodes:  3
app_nodes: 3
software_lb: True
##############################################################################
# DNS entries
##############################################################################
# Wildcard *.{{app_dns_prefix}}.{{public_hosted_zone}} must point to IP of LB
public_hosted_zone: example.com
local_hosted_zone: foo.bar
app_dns_prefix: apps


# Don't change unless you've re-named the LB vm
# if not using software LB set to DNS that resolves to Master LB
# Software example
# External LB
load_balancer_hostname: openshift-lb.{{ local_hosted_zone }}
# if no wildcard set this to your routers ext. ip
#load_balancer_ip:

# DNS that resolves to infra LB
# default subdomain to use for exposed routes, you should have wildcard dns
# for *.apps.test.example.com that points at your infra nodes which will run
# your router
wildcard_zone: "{{ app_dns_prefix }}.{{ public_hosted_zone }}"
openshift_master_cluster_public_hostname: openshift.{{ public_hosted_zone }}

##############################################################################
# Named Certs
##############################################################################
# Router Named Cert
#router_cert: '{"cafile": "/keys/letsencrypt/ca.cer", "certfile": "/keys/letsencrypt/fullchain.cer", "keyfile": "/keys/letsencrypt/openshift.example.com.key"}'

# Master Named Cert
#master_cert: '[{"cafile": "/keys/letsencrypt/ca.cer", "certfile": "/keys/letsencrypt/fullchain.cer", "keyfile": "/keys/letsencrypt/openshift.example.com.key", "names": ["openshift.example.com"]}]'


##############################################################################
# Identity Providers
##############################################################################
# Use 'htpasswd -n <user>' to generate password hash. (htpasswd from httpd-tools RPM)
# Example with admin:changeme
openshift_master_htpasswd_users: {'admin': '$apr1$zAhyA9Ko$rBxBOwAwwtRuuaw8OtCwH0'}
openshift_master_identity_providers: [{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider' }]

# example with multiple identityproviders
#openshift_master_identity_providers: [{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '/etc/origin/master/htpasswd'},{'name': 'google', 'login': 'true', 'challenge': 'false', 'kind': 'GoogleIdentityProvider', 'clientID': 'thisisaFakeTokenChange.apps.googleusercontent.com', 'clientSecret': 'FakeSecretForGoogleIdentity', 'hostedDomain': ''}]


##############################################################################
# Disable checking
##############################################################################
openshift_disable_check: memory_availability,disk_availability

# Needed to enable OCS dynamic provisioning without cloud-provider
dynamic_volumes_check: False

##############################################################################
# Networking
# Configure the multi-tenant SDN plugin
##############################################################################
os_sdn_network_plugin_name: 'redhat/openshift-ovs-multitenant'
#osm_cluster_network_cidr: 172.30.0.0/16
#openshift_portal_net:

##############################################################################
# Storage
##############################################################################
# host/dir for NFS - Not used if storage_type = dynamic
#storage_host: goliath.foo.bar
#storage_dir: "/hosted_engine"

# uses OCS by default
# dynamic for OCS
storage_type: dynamic

# Volume Sizes
metrics_volume_size: '10'
logging_volume_size: '10'
prometheus_volume_size: '10'
prometheus_alertmanager_size: '10'
prometheus_alertbuffer_size: '10'
cassandra_volume_size: '10'
registry_volume_size: '10'
logging_es_size: '10'

# OpenShift Container StorageClass
# Sizes in Gi
# infra usable storage needs to be greater than below calculations
# logging_volume_size * ec2_count_infra) + metrics_volume_size + prometheus_volume_size) * 1.3
ocs_infra_cluster_usable_storage: '200'
ocs_infra_cluster_allocated_storage: "{{ ((( logging_volume_size|int * infra_nodes |int ) + metrics_volume_size|int  + prometheus_volume_size|int + registry_volume_size | int) * 1.3 ) | round | int }}"
ocs_app_cluster_usable_storage: '100'
##############################################################################
# Metrics  / Logging
##############################################################################
# for best practices run through
# https://github.com/red-hat-storage/openshift-cic
deploy_ocs: true
deploy_grafana: true
deploy_prometheus: true
deploy_logging: true
deploy_metrics: true

##############################################################################
# Docker Storage
##############################################################################
# Defaults should be left alone
# PRE-reqs - sets up docker storage via the openshift installer
container_runtime_docker_storage_setup_device: /dev/vdb
container_runtime_docker_storage_type: 'overlay2'

##############################################################################
# UI customization
##############################################################################
#osm_project_request_message

##############################################################################
# Quota for emptydirs
##############################################################################
# Defaults should be left alone
# setup local quotas /var/lib/origin/openshift.local.volumes
local_volumes_device: '/dev/vdc'

##############################################################################
# Load Balancer
##############################################################################
# add firewall rules to lb/ normally 443/80 are not added by installer
# CNS will be unable to provision PVs until opened
r_openshift_loadbalancer_os_firewall_allow:
- service: haproxy stats
  port: "9000/tcp"
- service: haproxy balance
  port: "{{ openshift_master_api_port | default(8443) }}/tcp"
- service: haproxy https
  port: "443/tcp"
- service: haproxy http
  port: "80/tcp"

# LoadBalancer Adding 80/443 to haproxy config
openshift_loadbalancer_additional_frontends:
  - name: apps-http
    mode: tcp
    options:
      - "tcplog"
    binds:
      - "*:80"
    default_backend: apps-http
  - name: apps-https
    mode: tcp
    options:
      - "tcplog"
    binds:
      - "*:443"
    default_backend: apps-https
openshift_loadbalancer_additional_backends:
  - name: apps-http
    balance: source
    mode: tcp
    servers:
      - name: infra0
        address: "{{ groups['infra'].0 }}:80"
        opts: check
      - name: infra1
        address: "{{ groups['infra'].1 }}:80"
        opts: check
      - name: infra2
        address: "{{ groups['infra'].2 }}:80"
        opts: check
  - name: apps-https
    balance: source
    mode: tcp
    servers:
      - name: infra0
        address: "{{ groups['infra'].0 }}:443"
        opts: check
      - name: infra1
        address: "{{ groups['infra'].1 }}:443"
        opts: check
      - name: infra2
        address: "{{ groups['infra'].2 }}:443"
        opts: check
